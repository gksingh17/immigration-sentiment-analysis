{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc393beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vincent/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.classify.util as util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder as BCF\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import os.path\n",
    "from statistics import mode\n",
    "from nltk.classify import ClassifierI\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e868c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering(words):\n",
    "    words = word_tokenize(words)\n",
    "    scoreF = BigramAssocMeasures.chi_sq\n",
    "    #bigram count\n",
    "    n = 150\n",
    "    bigrams = BCF.from_words(words).nbest(scoreF, n)\n",
    "    #print(bigrams)\n",
    "    return dict([word,True] for word in itertools.chain(words, bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30ac418",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sen = open(\"positive.txt\", 'r', encoding = 'latin-1').read()\n",
    "neg_sen = open(\"negative.txt\", 'r', encoding = 'latin-1').read()\n",
    "\n",
    "emoji = open(\"emoji.txt\",'r', encoding = 'latin-1').read()\n",
    "pos_emoji = []\n",
    "neg_emoji = []\n",
    "for i in emoji.split('\\n'):\n",
    "    exp = ''\n",
    "    if i[len(i)-2] == '-':\n",
    "        for j in range(len(i) - 2):\n",
    "            exp += i[j]\n",
    "        neg_emoji.append(( {exp : True}, 'negative'))\n",
    "    else:\n",
    "        for j in range(len(i)-1):\n",
    "            exp += i[j]\n",
    "        pos_emoji.append(( {exp : True}, 'positive'))\n",
    "\n",
    "prev = [(featureEngineering(words), 'positive') for words in pos_sen.split('\\n')]\n",
    "nrev = [(featureEngineering(words), 'negative') for words in neg_sen.split('\\n')]\n",
    "\n",
    "ncutoff = int(len(nrev)*3/4)\n",
    "pcutoff = int(len(prev)*3/4)\n",
    "train_set = nrev[:ncutoff] + prev[:pcutoff] + pos_emoji + neg_emoji\n",
    "test_set = nrev[ncutoff:] + prev[pcutoff:]\n",
    "\n",
    "pos_set = prev + pos_emoji\n",
    "neg_set = nrev + neg_emoji\n",
    "\n",
    "real_classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Saving classifier\n",
    "save_doc = open(\"classifier.pickle\", 'wb')\n",
    "pickle.dump(real_classifier, save_doc)\n",
    "save_doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24949bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  78.20705176294074\n"
     ]
    }
   ],
   "source": [
    "#test_classifier = NaiveBayesClassifier.train(train_set)\n",
    "fl = open('classifier.pickle','rb')\n",
    "classifier = pickle.load(fl)\n",
    "fl.close()\n",
    "print (\"Accuracy is : \", util.accuracy(classifier, test_set) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723053e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f62448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
